{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio based human profiling\n",
    "---\n",
    "> This project is for profiling humans with audio based technologies. Especially, it mines and describes speech microfeatures, and explores their link to myriad of human descriptors / profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update ~11/20/2017\n",
    "\n",
    "### Literature review\n",
    "Review literature regarding speech features and usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update ~11/27/2017\n",
    "\n",
    "### Speech features\n",
    "\n",
    "Need\n",
    "\n",
    "1. large between-speaker variability and small within-speaker variability\n",
    "2. robust against noise and distortion\n",
    "3. obtainable\n",
    "4. frequent\n",
    "5. easy to measure\n",
    "6. difficult to mimic\n",
    "7. not affected by speaker's health or long-term variations in voice\n",
    "8. low dimensional\n",
    "\n",
    "Classification\n",
    "\n",
    "1. High-level: conversational, word & sentence level\n",
    "    1. Phones\n",
    "    2. Idiolect\n",
    "    3. Personal lexicon\n",
    "    4. Semantics\n",
    "    5. Accent\n",
    "    6. Pronunciation\n",
    "2. Mid-level: prosodic & spectro-temporal, tens or hundreds of ms, voice source / glottal flow related\n",
    "    1. Pitch\n",
    "    2. Energy\n",
    "    3. Duration\n",
    "    4. Rhythm\n",
    "    5. Temporal features: pitch onset and offset\n",
    "3. Low-level: spectral, short-term, frame level, 20-30ms\n",
    "    1. Spectrum: harmonics, cepstral, LPCs\n",
    "    2. Glottal pulse features\n",
    "4. Micro-level: transient, 1-20ms, fine-grained, spreading over entire signal\n",
    "    1. Aphonicity: unvoiced sound\n",
    "    2. Biphonicity: mix of two sounds\n",
    "    3. Breathiness: intra and between speech\n",
    "    4. Creakiness: harsh, high-pitched\n",
    "    5. Glottalization: complete or partial closure of the glottis during the articulation of another sound. e.g., glottal 'T'\n",
    "    6. Hoarseness\n",
    "    7. Nasality\n",
    "    8. Jitter\n",
    "    9. Vocal fry\n",
    "    10. Resonant\n",
    "    11. Shimmer\n",
    "\n",
    "    ...\n",
    "5. Latent: hidden, confounding, different domain\n",
    "    1. Bottleneck\n",
    "    2. Z\n",
    "\n",
    "Remarks\n",
    "\n",
    "1. Higher-level features are behavioral: learned, related to social status, education, origin, upbringing, etc.\n",
    "Lower-level features are organic: vocal folds, vocal tract, etc.\n",
    "\n",
    "2. High and mid-level features are more robust, but less discriminative, easier to mimic, difficult to extract, need more training data.\n",
    "Low-level features are easy to extract, need less training data, but more affected by noise and mismatch.\n",
    "\n",
    "3. Current the literature often uses combination/fusion of the high, mid, low-level features.\n",
    "\n",
    "4. Micro-level features are difficult to measure.\n",
    "\n",
    "5. Latent features have confounding dimensions, and are hard to link to high, mid, low-level features.\n",
    "\n",
    "### Re-visit feature discovery via network dissection\n",
    "\n",
    "1. Last time: failed may be due to too short segments.\n",
    "This time: use longer speech segments.\n",
    "\n",
    "2. On classification tasks.\n",
    "\n",
    "3. First step: mask neurons to observe effects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
